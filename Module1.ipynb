{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Basics\n",
    "In this module, you'll be acquiring and handling datasets. You will be using the Cinema Data, Salary Data and Reviews Data for the tasks in this module. <br> <br>\n",
    "**Pipeline:**\n",
    "* Acquiring the data\n",
    "* Handling files and formats\n",
    "* Data Analysis\n",
    "* Prediction\n",
    "* Analysing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Data Acquisition\n",
    "* Retrieve the CinemaData dataset from Firebase, convert it to a CSV and save it in the 'Data' folder as 'CinemaData.csv'. You may use shell scripts, other packages and any other resources you require to do this. The database can be accessed with a HTTP request, ask a TA for the link. <br> \n",
    "* Using `wget`, download the 'SalaryData.txt' and save it in the 'Data' folder. Convert it to a CSV named 'SalaryData.csv' and save it in the same folder. It is avaliable at this link: <br>\n",
    "http://rebrand.ly/ml_salarydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 849446 / 849446"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://sf-mlbasics.firebaseio.com/CinemaData.json\"\n",
    "req = wget.download(url = URL)\n",
    "data = pd.read_json(req)\n",
    "data.to_csv('D:\\Work\\SF\\MLBasics-master\\Data\\CinemaData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = \"http://rebrand.ly/ml_salarydata\"\n",
    "req = requests.get(URL)\n",
    "\n",
    "with open (r'D:\\Work\\SF\\MLBasics-master\\Data\\SalaryData.json','w') as f:\n",
    "    f.write(req.text)\n",
    "\n",
    "df = pd.read_csv(URL)\n",
    "df.to_csv('D:\\Work\\SF\\MLBasics-master\\Data\\SalaryData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Dataset Handling\n",
    "* You can find the Reviews Data in a RAR file in the 'Data' directory. Extract this dataset and use it for this module.\n",
    "\n",
    "* The dataset contains positive and negative movie reviews. The files 'Positive_Reviews.txt' and 'Negative_Reviews.txt' contain names of files having positive and negative reviews respectively. Create two directories ‘pos’ and ‘neg’, and segregate the reviews accordingly into the two directories.\n",
    "\n",
    "* Load ‘cv000_29590.csv’ and report the number of words present in the first column.\n",
    "\n",
    "* Find the number of unique words in the first column. For this task, ignore punctuations, that is, punctuations are not considered as a word or a part of it.\n",
    "\n",
    "* Lookups: OS module, String functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('Data\\\\pos')\n",
    "os.mkdir('Data\\\\neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import unrar\n",
    "import rarfile\n",
    "from pyunpack import Archive\n",
    "import shutil      #copy contemt of source file to destination file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rar = rarfile.RarFile(r'D:\\Work\\SF\\MLBasics-master\\Data\\Reviews.rar')\n",
    "\n",
    "lst1 = []\n",
    "pos = []\n",
    "neg = []\n",
    "\n",
    "#extracting file names\n",
    "Archive('Data\\\\Reviews.rar').extractall('Data\\\\')\n",
    "strdir = r'D:\\Work\\SF\\MLBasics-master\\Data\\Assignment_1_a\\Reviews'\n",
    "directory = os.fsencode(strdir)\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".txt\"): \n",
    "        lst1.append(filename)\n",
    "        continue\n",
    "    else:\n",
    "         continue\n",
    "            \n",
    "with open(r'D:\\Work\\SF\\MLBasics-master\\Data\\Assignment_1_a\\Positive_Reviews.txt','r') as pf:\n",
    "    contents = pf.read()\n",
    "    contents = contents.replace('\"','').replace(\"'\",'').replace('[','').replace(']','').replace(' ','')\n",
    "    pos = contents.split(\",\")\n",
    "    \n",
    "with open(r'D:\\Work\\SF\\MLBasics-master\\Data\\Assignment_1_a\\Negative_Reviews.txt','r') as nf:\n",
    "    contents = nf.read()\n",
    "    contents = contents.replace('\"','').replace(\"'\",'').replace('[','').replace(']','').replace(' ','')\n",
    "    neg = contents.split(\",\")\n",
    "      \n",
    "#moving to the desired location\n",
    "for i in lst1:\n",
    "    if i in pos:\n",
    "        shutil.copy('D:\\\\Work\\\\SF\\MLBasics-master\\\\Data\\\\Assignment_1_a\\\\Reviews\\\\'+i,'D:\\Work\\SF\\MLBasics-master\\\\Data\\\\pos')\n",
    "    elif i in neg:\n",
    "        shutil.copy('D:\\\\Work\\\\SF\\MLBasics-master\\\\Data\\\\Assignment_1_a\\\\Reviews\\\\'+i,'D:\\Work\\SF\\MLBasics-master\\\\Data\\\\neg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words:  239\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "df = pd.read_csv('D:\\Work\\SF\\MLBasics-master\\\\Data\\\\pos\\\\cv000_29590.txt')\n",
    "df = df.iloc[:,0].values\n",
    "words = []\n",
    "for line in df:\n",
    "        line = line.replace('.','').replace('(','').replace(')','').replace('?','')\n",
    "        words.extend(line.split())\n",
    "print(\"The number of words: \",len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words:  174\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "df = pd.read_csv('D:\\Work\\SF\\MLBasics-master\\\\Data\\\\pos\\\\cv000_29590.txt')\n",
    "df = df.iloc[:,0].values\n",
    "words = set()\n",
    "for line in df:\n",
    "        line = line.replace('.','').replace('(','').replace(')','').replace('?','')\n",
    "        for a in line.split():\n",
    "            words.add(a)\n",
    "print(\"The number of unique words: \",len(words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
